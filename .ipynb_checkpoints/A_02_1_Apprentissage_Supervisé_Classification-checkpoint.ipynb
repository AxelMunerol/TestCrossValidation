{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c05579b-e221-4dec-b05d-19745ce29df7",
   "metadata": {},
   "source": [
    "# **Introduction à l'Apprentissage Supervisé et à la Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025f87e-e8d6-4ca2-aa69-d38135b0c132",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Introduction\n",
    "\n",
    "Dans cette séance, nous explorerons les bases de l’**apprentissage supervisé**, une méthode fondamentale du Machine Learning où un modèle apprend à prédire une valeur cible en s’appuyant sur des données déjà étiquetées. Nous nous concentrerons spécifiquement sur la **classification**, une tâche consistant à prédire la catégorie ou la classe d'une observation en fonction de ses caractéristiques. \n",
    "\n",
    "Pour bien comprendre ces concepts, nous aborderons les étapes clés du workflow de l’apprentissage supervisé, de la préparation des données jusqu'à l'évaluation des modèles. Nous appliquerons ensuite ces notions sur un dataset réel, le célèbre **dataset Iris**, qui servira de base pour illustrer chaque étape, construire et évaluer plusieurs modèles de classification.\n",
    "\n",
    "### Objectifs de la Séance\n",
    "\n",
    "- Découvrir les concepts théoriques de l’**apprentissage supervisé** et de la **classification**.\n",
    "- Comprendre les étapes d’un projet de Machine Learning supervisé, depuis l’exploration des données jusqu’à l’évaluation des modèles.\n",
    "- Mettre en pratique ces concepts en entraînant différents modèles pour prédire des classes sur des données réelles.\n",
    "\n",
    "Cette séance vous apportera une compréhension concrète de la classification, un pilier essentiel du Machine Learning, en vous guidant pas à pas, de la théorie à la pratique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625981cd-b68c-4242-8891-bbc61663bf72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## **Introduction à l’Apprentissage Supervisé**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1065947a-0991-42ca-bcc7-3b3bcbcae6b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Définition de l'Apprentissage Supervisé**\n",
    "\n",
    "L'apprentissage supervisé est une branche fondamentale du Machine Learning où le modèle apprend à partir de données déjà étiquetées, c’est-à-dire des données pour lesquelles nous connaissons les réponses correctes. L'objectif est de permettre au modèle d’**apprendre des relations** entre les données d’entrée (appelées caractéristiques ou *features*) et les réponses (*target*) de façon à pouvoir **prédire la réponse** pour de nouvelles données inconnues.\n",
    "\n",
    "**Exemples d'applications d'apprentissage supervisé :**\n",
    "- Détection de spam (prédire si un email est spam ou non).\n",
    "- Prédiction du prix de l’immobilier (évaluer la valeur d’une maison en fonction de ses caractéristiques).\n",
    "\n",
    "\n",
    "### **Types de Tâches Supervisées**\n",
    "\n",
    "L'apprentissage supervisé inclut principalement deux types de tâches :\n",
    "\n",
    "- **Classification** : Prédire une **catégorie** ou **classe**. Exemple : classifier un email comme spam ou non-spam, ou prédire l'espèce d'une fleur en fonction de ses caractéristiques (longueur et largeur de pétales, etc.).\n",
    "- **Régression** : Prédire une **valeur continue**. Exemple : estimer le prix d'une maison en fonction de ses caractéristiques, ou prédire le revenu annuel d'un individu.\n",
    "\n",
    "> Ces tâches dépendent du type de variable cible (*target*). Si la cible est une catégorie, c'est une classification. Si la cible est une valeur continue, c'est une régression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adacd8a8-07a1-4e86-84d6-3eaef6d494de",
   "metadata": {},
   "source": [
    "#### Quiz : Tâche de Régression ou Classification ?\n",
    "\n",
    "Pour chaque scénario ci-dessous, indiquez s’il s’agit d’une tâche de **régression** ou de **classification**.\n",
    "\n",
    "1. **Prévision des ventes** : Une entreprise souhaite prédire le nombre d’unités qu’elle vendra de son nouveau produit au cours du prochain mois.\n",
    "   - **Régression** ou **Classification** ?\n",
    "\n",
    "\n",
    "2. **Détection d'email spam** : Un modèle doit classifier les emails comme étant soit du spam, soit du non-spam.\n",
    "   - **Régression** ou **Classification** ?\n",
    "\n",
    "\n",
    "3. **Prédiction du prix de l'immobilier** : Un modèle est utilisé pour estimer la valeur d’une maison en fonction de ses caractéristiques (taille, nombre de chambres, localisation).\n",
    "   - **Régression** ou **Classification** ?\n",
    "\n",
    "\n",
    "4. **Diagnostic médical** : Un modèle est entraîné pour prédire si un patient est atteint ou non d'une certaine maladie en fonction de ses antécédents médicaux et de ses résultats d'examens.\n",
    "   - **Régression** ou **Classification** ?\n",
    "\n",
    "\n",
    "5. **Prédiction du revenu annuel** : Un modèle doit estimer le revenu annuel d’un individu en fonction de plusieurs caractéristiques démographiques et professionnelles.\n",
    "   - **Régression** ou **Classification** ?\n",
    "\n",
    "\n",
    "6. **Classification des genres musicaux** : Un modèle est utilisé pour classifier des morceaux de musique en fonction de leur genre (par exemple, rock, jazz, classique).\n",
    "   - **Régression** ou **Classification** ?\n",
    "\n",
    "\n",
    "7. **Estimation de la température** : Un modèle est utilisé pour prédire la température moyenne d’une ville pour le jour suivant en fonction des données météorologiques récentes.\n",
    "   - **Régression** ou **Classification** ?\n",
    "\n",
    "\n",
    "8. **Prévision des scores scolaires** : Un modèle est utilisé pour prédire le score final d’un étudiant en fonction de son temps d’étude et de ses notes passées.\n",
    "   - **Régression** ou **Classification** ?\n",
    "\n",
    "\n",
    "9. **Détection de fraude** : Une banque utilise un modèle pour identifier les transactions suspectes et les classer comme « frauduleuses » ou « non frauduleuses ».\n",
    "   - **Régression** ou **Classification** ?\n",
    "\n",
    "\n",
    "10. **Prédiction du taux de satisfaction client** : Une entreprise souhaite prédire si un client sera « satisfait », « neutre » ou « insatisfait » après avoir utilisé un service.\n",
    "    - **Régression** ou **Classification** ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0d6e1-9bcd-4292-a7fe-2e5ef7c6fcdc",
   "metadata": {},
   "source": [
    "### **Composantes de l’Apprentissage Supervisé**\n",
    "\n",
    "Pour bien comprendre l'apprentissage supervisé, il est essentiel de connaître les composantes principales d'un dataset et leur rôle :\n",
    "\n",
    "- **Features (Caractéristiques)** : Les variables d’entrée qui décrivent chaque observation dans le dataset (par exemple, la longueur et la largeur des pétales pour classifier une fleur).\n",
    "- **Target (Cible)** : La variable que nous essayons de prédire à partir des caractéristiques. Dans notre cas, la cible pourrait être l'espèce de la fleur (setosa, versicolor, virginica).\n",
    "- **Training Data (Données d’Entraînement)** : Sous-ensemble du dataset utilisé pour entraîner le modèle, afin qu'il apprenne à associer les caractéristiques à la cible.\n",
    "- **Test Data (Données de Test)** : Sous-ensemble du dataset utilisé pour évaluer le modèle après l’entraînement et mesurer sa capacité de généralisation sur des données nouvelles.\n",
    "\n",
    "\n",
    "\n",
    "## **Workflow Général en Apprentissage Supervisé**\n",
    "\n",
    "Le workflow d'un projet de Machine Learning supervisé comporte plusieurs étapes. Voici une représentation visuelle du processus :\n",
    "\n",
    "```markdown\n",
    "\n",
    "   ┌───────────────┐      ┌───────────────┐      ┌───────────────┐       ┌───────────────┐\n",
    "   │   Dataset     │ ---> │   Exploration │ ---> │ Preprocessing │ --->  │   Splitting   │ \n",
    "   └───────────────┘      └───────────────┘      └───────────────┘       └───────────────┘  \n",
    "                                                                               │                       \n",
    "                                                                  └─────────────────────────────┘\n",
    "                                                                      │                   │ \n",
    "                                                                      ▼                   ▼\n",
    "                                                            ┌───────────────┐         ┌───────────────┐\n",
    "                                                            │ Training Data │         │   Test Data   │\n",
    "                                                            └───────────────┘         └───────────────┘\n",
    "                                                                   └─────────────────────────────┘\n",
    "                                                                       │                   │ \n",
    "                                                                       ▼                   ▼\n",
    "                                                           ┌────────────────┐          ┌──────────────────┐\n",
    "                                                           │ Model Training │          │ Model Evaluation │\n",
    "                                                           │  (sur Train)   │          │    (sur Test)    │\n",
    "                                                           └────────────────┘          └──────────────────┘\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "**Étapes du Workflow :**\n",
    "\n",
    "1. **Dataset** : Point de départ, le dataset contient les caractéristiques (*features*) et la cible (*target*) pour chaque observation.\n",
    "   \n",
    "2. **Exploration** : Analyse et visualisation des données pour identifier leur structure, leur distribution et des caractéristiques spécifiques. Cela permet de mieux comprendre les données avant de les transformer.\n",
    "\n",
    "3. **Prétraitement** : Préparation des données en appliquant des transformations comme la gestion des valeurs manquantes, l’encodage des variables catégorielles et la normalisation si nécessaire. Ces étapes assurent la qualité et la cohérence des données pour l’entraînement du modèle.\n",
    "\n",
    "4. **Splitting (Division)** : Division du dataset en **Training Data** (données d’entraînement) et **Test Data** (données de test) pour garantir une évaluation fiable des performances du modèle. Cette séparation permet d'entraîner le modèle sur une partie des données, puis de le tester sur des données qu'il n’a jamais vues.\n",
    "\n",
    "5. **Model Training (Entraînement du Modèle)** : Entraînement du modèle sur l'ensemble des données d’entraînement (Training Data). L’objectif est que le modèle \"apprenne\" les relations entre les caractéristiques et la cible à partir des exemples.\n",
    "\n",
    "6. **Model Evaluation (Évaluation du Modèle)** : Test du modèle sur l’ensemble des données de test (Test Data) en utilisant des métriques adaptées à la tâche de classification, telles que l’exactitude, le rappel, et le F1-score. Cette étape permet de mesurer la capacité du modèle à généraliser et à faire des prédictions fiables sur de nouvelles données.\n",
    "\n",
    "> **Note :** Ce workflow assure que le modèle apprend à partir des données d’entraînement sans surapprendre, tout en offrant une évaluation réaliste de ses performances sur de nouvelles données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95882a95-b6c4-48c3-a57a-1f47d405825f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## **Introduction a la Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe81dc2-c7db-4ea2-bbc9-432e2f2fce55",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Définition de la Classification\n",
    "\n",
    "La **classification** est une tâche fondamentale en Machine Learning qui consiste à assigner une **catégorie** ou **classe** à une observation en fonction de ses caractéristiques. Le modèle de classification apprend à partir de données annotées pour reconnaître des motifs et peut ensuite prédire la classe d’une nouvelle donnée. C’est un type de tâche d’**apprentissage supervisé**, car les données d'entraînement contiennent les labels de classe connus.\n",
    "\n",
    "\n",
    "<img src=\"classification.png\" alt=\"classification.png\" width=\"400\" height=\"300\">\n",
    "\n",
    "### Types de Classification\n",
    "\n",
    "Il existe différents types de classification en fonction du nombre et de la nature des classes :\n",
    "\n",
    "1. **Classification Binaire** : Le modèle attribue une observation à l’une des **deux classes possibles**. Exemple : détection d'email comme **spam** ou **non-spam**.\n",
    "2. **Classification Multiclasse** : Le modèle attribue une observation à l’une de **plusieurs classes**. Exemple : classifier une image comme représentant un **chat**, un **chien**, ou un **oiseau**.\n",
    "3. **Classification Multi-étiquettes** : Une observation peut appartenir à **plusieurs classes simultanément**. Exemple : étiqueter une image qui pourrait contenir à la fois **une personne** et **un animal**.\n",
    "\n",
    "\n",
    "### Exemple de Classification\n",
    "\n",
    "Imaginons un modèle de classification pour filtrer les emails en **Spam** ou **Non-Spam**. Le modèle examine les caractéristiques des emails (par exemple, la présence de certains mots) et apprend à prédire si un nouvel email est probablement du spam.\n",
    "\n",
    "> **Exemple de Dataset** :\n",
    ">\n",
    "> | Email               | Contient \"Offre\" ? | Contient \"Promo\" ? | Spam ? |\n",
    "> |---------------------|--------------------|---------------------|--------|\n",
    "> | \"Promo spéciale !\" | Oui                | Oui                | Oui    |\n",
    "> | \"Rendez-vous...\"   | Non                | Non                | Non    |\n",
    "> | \"Offre de prêt\"    | Oui                | Non                | Oui    |\n",
    "\n",
    "Dans cet exemple simplifié, le modèle apprend que les mots-clés \"Offre\" et \"Promo\" sont associés aux emails de spam et utilise cette information pour classer de nouveaux emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9eb01b-2842-4a85-a866-d65ab3dd1e3c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Introduction au Dataset Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f49e36-0106-48c8-ab3c-fc3b068bd17d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Dans cette étape, nous allons introduire le dataset **Iris**, un dataset classique pour la classification en apprentissage supervisé.\n",
    "\n",
    "Le dataset Iris contient 150 observations réparties en trois classes de fleurs : **Setosa**, **Versicolor**, et **Virginica**. Chaque observation comporte quatre caractéristiques principales mesurées en centimètres : la longueur et la largeur des pétales, ainsi que la longueur et la largeur des sépales.\n",
    "\n",
    "Les colonnes du dataset sont :\n",
    "\n",
    "1. `sepal_length` : Longueur du sépale\n",
    "2. `sepal_width` : Largeur du sépale\n",
    "3. `petal_length` : Longueur du pétale\n",
    "4. `petal_width` : Largeur du pétale\n",
    "5. `species` : La classe de la fleur (Setosa, Versicolor, Virginica)\n",
    "\n",
    "L'objectif est de prédire la classe d'une fleur en fonction de ses caractéristiques.\n",
    "\n",
    "![Iris_Flowers](Iris_Flowers.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6645b1-e0e7-4621-a6e9-f3e5f0ac6025",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Étape 1 : Charger le Dataset Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c84ea-2e8e-43dc-813e-23cd3ff248f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Nous allons charger le dataset Iris, qui est disponible directement dans `sklearn`. `load_iris()` permet de récupérer les données et les informations nécessaires pour une analyse complète.\n",
    "\n",
    "### Instructions :\n",
    "\n",
    "1. **Importez les bibliothèques nécessaires** :\n",
    "   - **`pandas`** pour la manipulation des données.\n",
    "   - **`matplotlib.pyplot`** et **`seaborn`** pour la visualisation.\n",
    "   - **`sklearn.datasets`** pour charger le dataset Iris intégré.\n",
    "\n",
    "2. **Charger le Dataset avec `load_iris()`** :\n",
    "   - Utilisez `load_iris()` de `sklearn.datasets` pour charger les données. Cette fonction renvoie un objet `Bunch`, similaire à un dictionnaire, contenant les données et des informations associées.\n",
    "\n",
    "3. **Explorer les Attributs du Dataset** :\n",
    "   - **`data`** : Contient les valeurs des caractéristiques pour chaque observation (longueur/largeur des sépales et pétales).\n",
    "   - **`target`** : Contient les labels de classe sous forme de valeurs numériques (0, 1, 2) correspondant aux trois espèces d’iris.\n",
    "   - **`feature_names`** : Liste des noms des caractéristiques.\n",
    "   - **`target_names`** : Liste des noms des classes (Setosa, Versicolor, Virginica).\n",
    "   - **`DESCR`** : Une description textuelle du dataset, expliquant ses caractéristiques et sa structure.\n",
    "\n",
    "4. **Créer un DataFrame avec les Caractéristiques et les Labels** :\n",
    "   - Utilisez `data` et `feature_names` pour créer un DataFrame `pandas`. Les noms des caractéristiques serviront de noms de colonnes.\n",
    "   - Ajoutez une colonne `species` pour les labels de classe, en utilisant `target`. Pour une meilleure lisibilité, mappez chaque valeur numérique de `target` aux noms de classes correspondants (`target_names`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c4cda-ce04-4c46-8fe7-764a9718ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour charger le dataset Iris "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb528fb6-7896-4913-82a1-bf9dc66c7e2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Étape 2 : Exploration des Données (EDA) avec le Dataset Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c883dd-1b41-4bcb-b9ad-1280597db883",
   "metadata": {
    "tags": []
   },
   "source": [
    "L’exploration des données, ou **Exploratory Data Analysis (EDA)**, est une étape essentielle pour mieux comprendre la structure, les relations, et les particularités des données avant de construire un modèle. Cette étape permet de :\n",
    "\n",
    "- Identifier la distribution des données.\n",
    "- Détecter les éventuels problèmes, comme les valeurs manquantes ou les anomalies.\n",
    "- Comprendre les relations entre les caractéristiques et les classes cibles.\n",
    "\n",
    "**Instructions :**\n",
    "\n",
    "1. **Afficher les premières lignes du DataFrame**  \n",
    "   Utilisez la méthode `.head()` sur le DataFrame pour afficher les cinq premières lignes. Cette vue rapide vous donnera un aperçu de la structure et des types de données des colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ab023-ecaf-4334-a0ab-9d80fa3b541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour afficher les premières lignes du DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2188302-ebdb-4495-96cc-4488467dda41",
   "metadata": {},
   "source": [
    "> **Question :** Que remarquez-vous dans les colonnes et les types de données du DataFrame ? Les noms des caractéristiques sont-ils clairs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daed9ea-d2b7-4784-a96f-c2ac049aaec8",
   "metadata": {},
   "source": [
    "2. **Vérifier les informations de base sur le DataFrame**  \n",
    "   Utilisez la méthode `.info()` sur le DataFrame pour afficher des informations générales comme le type de chaque colonne, la présence éventuelle de valeurs manquantes et le nombre total d’observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359b7496-5844-489c-8dcf-4370418f5f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour afficher les informations de base sur le DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fbbf1-e032-464e-bcbb-72ef09ade7d7",
   "metadata": {},
   "source": [
    "> **Question :** Y a-t-il des valeurs manquantes dans ce dataset ? Quel type de données chaque colonne contient-elle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100bfe2d-44db-44c8-ad6a-b8ddb56d4781",
   "metadata": {},
   "source": [
    "3. **Examiner les statistiques descriptives**  \n",
    "   Utilisez la méthode `.describe()` pour afficher les statistiques de base (moyenne, écart-type, minimum, maximum) de chaque caractéristique numérique afin de comprendre leur distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e7ba0-10aa-41d1-98e8-ccdaceb1dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour examiner les statistiques descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb314e9b-5eac-4e3f-b723-127bbf141b1b",
   "metadata": {},
   "source": [
    "> **Question :** Les caractéristiques ont-elles des plages de valeurs similaires ou différentes ? Que pouvez-vous en déduire quant à la variabilité des données ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601644da-6a13-46b3-bcd6-4c4992cec420",
   "metadata": {},
   "source": [
    "4. **Analyser la répartition des classes**  \n",
    "   Utilisez la méthode `.value_counts()` sur la colonne des labels pour compter le nombre d’observations dans chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8c3aa0-8f4e-49ca-adfb-872b35e9e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour analyser la répartition des classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aecfcf-d3ad-4709-afc9-e1c30ea9c2b1",
   "metadata": {},
   "source": [
    "> **Question :** Comment les classes sont-elles réparties ? Y a-t-il un équilibre entre elles, ou l’une des classes est-elle sur-représentée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e84943-255a-48ec-a33c-e7c8b3e1abb0",
   "metadata": {},
   "source": [
    "5. **Visualiser la distribution des caractéristiques**  \n",
    "   Utilisez des graphiques comme `sns.histplot()` ou `sns.boxplot()` pour créer des histogrammes ou des boxplots et visualiser la distribution de chaque caractéristique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630d579-7754-47c3-bf23-670a3e407fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour visualiser la distribution des caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ab399-d325-4238-b9ab-8652d99e53b0",
   "metadata": {},
   "source": [
    "> **Question :** Quels schémas ou anomalies remarquez-vous dans la distribution des caractéristiques ? Certaines caractéristiques semblent-elles mieux différencier les classes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f360da-9cce-4b15-8af3-0ea980bbb8b4",
   "metadata": {},
   "source": [
    "6. **Examiner les relations entre les caractéristiques**  \n",
    "   Utilisez des diagrammes de dispersion (scatter plots) avec `sns.pairplot()` pour visualiser les relations entre les caractéristiques et colorer les points selon la classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3dd6b-b523-4159-a743-0184d1a27ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour examiner les relations entre les caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22dc389-17cf-4c65-9864-98f529befe69",
   "metadata": {},
   "source": [
    "> **Question :** Certaines paires de caractéristiques semblent-elles montrer une séparation claire entre les classes ? Si oui, lesquelles ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c933d62-5435-4736-9cac-99b7496a58c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Étape 3 : Prétraitement des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4cc2c-7605-4b5f-998f-eb68f9b25e44",
   "metadata": {},
   "source": [
    "Le prétraitement est une étape cruciale pour préparer les données avant d'entraîner le modèle. Certaines étapes doivent être appliquées uniquement après la séparation des données en ensembles d'entraînement et de test pour éviter le **data leakage** (fuite de données)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532798ad-3ab5-450f-8aad-aa5d81cfceaa",
   "metadata": {},
   "source": [
    "> Le **data leakage** survient lorsque des informations du jeu de test influencent le jeu d'entraînement, ce qui fausse les résultats en donnant au modèle un \"aperçu\" des données de test pendant son entraînement. Cela peut conduire à des performances trompeuses qui ne se généralisent pas bien aux nouvelles données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801f8d1-8986-43db-ab12-8087d2fe8cd6",
   "metadata": {},
   "source": [
    "1. **Vérifier les doublons**  \n",
    "   Utilisez la méthode `.duplicated()` pour détecter les lignes en double et `.drop_duplicates()` pour les supprimer si nécessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7592f9e6-1430-40f5-9ad0-a66fd469b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour vérifier et supprimer les doublons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99600a4b-3643-4e5d-9689-737763b15353",
   "metadata": {},
   "source": [
    " > **Question :** Avez-vous trouvé des doublons dans le dataset ? Si oui, combien ? Pensez-vous que les garder ou les supprimer influencerait l’analyse ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f67912-f620-4a06-845c-900e83a7fe88",
   "metadata": {},
   "source": [
    "2. **Encodage des labels**  \n",
    "   Vérifiez que la colonne des classes (`species`) est sous forme numérique. Si elle est en format texte, utilisez `pd.Categorical` ou `LabelEncoder` de `sklearn` pour encoder les classes en valeurs numériques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b646e-0983-4b3e-ac9a-80927f105ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour encoder les labels si nécessaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598e2b8-f056-45c1-a56f-604b67d02175",
   "metadata": {},
   "source": [
    " > **Question :** Quelle méthode utiliseriez-vous pour encoder les classes de manière à ce que le modèle puisse les interpréter ? L’encodage est-il déjà effectué ou est-il nécessaire de l’ajouter ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394efae8-f7ea-4e7b-990f-cbba43afc8f6",
   "metadata": {},
   "source": [
    "3. **Standardisation ou Normalisation (à faire après la séparation train/test, si necessaire)**  \n",
    "   La standardisation ou normalisation des caractéristiques est recommandée pour certains modèles (comme les modèles sensibles à la distance). Utilisez `StandardScaler` de `sklearn.preprocessing` après la séparation des données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed7438-b18d-4aeb-a779-1e6e369887b0",
   "metadata": {},
   "source": [
    "> **Question :** Pourquoi est-il important de standardiser les caractéristiques après la séparation en train et test ? Que pourrait-il se passer si vous appliquez cette transformation avant la séparation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a928b33-e97e-4294-a76c-b2743b20c1b1",
   "metadata": {},
   "source": [
    "4. **Vérification finale du DataFrame**  \n",
    "   Assurez-vous que toutes les données sont prêtes pour la modélisation. Vérifiez que les colonnes sont encodées correctement, que le DataFrame ne contient plus de valeurs manquantes ou d’incohérences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e993d083-52a9-45f6-8771-44b2dd0e4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour la vérification finale du DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004989d8-8be6-4862-96f9-647c1fefd406",
   "metadata": {},
   "source": [
    "> **Question :** Le DataFrame semble-t-il maintenant prêt pour la modélisation ? Quelles autres transformations envisageriez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0379cb-413f-428c-9b87-b4090e399382",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Étape 4 : Diviser les données en ensembles d’entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9015da-a6c2-40d3-852b-eb0d109184b8",
   "metadata": {},
   "source": [
    "### 1. Séparation de Features et de Target\n",
    "\n",
    "1. **Sélectionner les caractéristiques (features)**  \n",
    "   Dans le dataset Iris, les caractéristiques sont les colonnes numériques représentant les mesures de la fleur (longueur et largeur des sépales et pétales). Assignez ces colonnes à une variable, par exemple `X`.\n",
    "\n",
    "2. **Définir la cible (target)**  \n",
    "   La cible, ou `target`, est la variable que vous voulez prédire. Dans ce cas, il s'agit de la colonne `species`, qui contient les classes des fleurs. Assignez cette colonne à une variable, par exemple `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a710626-2ed5-471f-8f9d-74b463348557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour séparer les caractéristiques et la cible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08282fd0-c590-46f2-b1bb-306b75ee6ddc",
   "metadata": {},
   "source": [
    "Une fois les caractéristiques (`X`) et la cible (`y`) définies, il est essentiel de diviser les données en deux ensembles distincts pour évaluer la capacité du modèle à généraliser sur de nouvelles données. Cette division nous aide à obtenir une estimation réaliste des performances en conditions réelles, sans \"voir\" les données de test lors de l'entraînement.\n",
    "\n",
    "Pour cela, nous utilisons la fonction `train_test_split` de `sklearn.model_selection`, qui renvoie quatre objets distincts : les caractéristiques et les cibles pour les ensembles d’entraînement et de test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598de44-45b9-4837-b8ca-cbeae09a1064",
   "metadata": {},
   "source": [
    "### 2. Division des données avec la fonction `train_test_split`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f37b2-c515-4e13-8afd-ee7e6f0a3a09",
   "metadata": {},
   "source": [
    "### `train_test_split`\n",
    "\n",
    "Voici comment utiliser `train_test_split` et ce que chaque variable représente :\n",
    "\n",
    "```python\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "```\n",
    "\n",
    "- **Ce que retourne `train_test_split`** :\n",
    "  - **`X_train`** : Caractéristiques pour l’entraînement\n",
    "  - **`X_test`** : Caractéristiques pour le test\n",
    "  - **`y_train`** : Cible pour l’entraînement\n",
    "  - **`y_test`** : Cible pour le test\n",
    "\n",
    "Ces quatre objets forment les ensembles que vous utiliserez pour construire et évaluer le modèle. `X_train` et `y_train` seront utilisés pour l’entraînement, tandis que `X_test` et `y_test` serviront à évaluer ses performances sur des données inédites.\n",
    "\n",
    "\n",
    "#### Explication des paramètres\n",
    "\n",
    "- **Pourquoi diviser ?**  \n",
    "  La division des données est essentielle pour tester la capacité du modèle à généraliser, c'est-à-dire à bien fonctionner sur des données qu’il n’a jamais vues pendant l’entraînement. En général, on utilise 80 % des données pour l’entraînement et 20 % pour le test.\n",
    "\n",
    "- **Paramètre `test_size=0.2`**  \n",
    "  Ce paramètre définit la proportion des données à utiliser pour le test. Avec `test_size=0.2`, 20 % des données sont affectées à l’ensemble de test et 80 % à l’ensemble d’entraînement. Vous pouvez ajuster cette valeur (par exemple, `test_size=0.3` pour 30 % des données en test) en fonction des besoins de votre projet.\n",
    "\n",
    "- **Paramètre `random_state=42`**  \n",
    "  `random_state` est un entier qui rend la division reproductible. Fixer `random_state=42` garantit que la division reste identique à chaque exécution, ce qui est crucial pour obtenir des résultats cohérents.  \n",
    "  > **Note :** Changer la valeur de `random_state` modifie l’ordre des données dans chaque division, mais les proportions entre `train` et `test` restent identiques.\n",
    "\n",
    "- **Paramètre `shuffle=True`**  \n",
    "  `shuffle` indique si les données doivent être mélangées avant la division. En général, il est préférable de mélanger les données pour s’assurer qu’elles sont bien distribuées entre les ensembles d’entraînement et de test, en particulier si les données sont ordonnées. Par défaut, `shuffle` est défini sur `True`.  \n",
    "  > **Note :** Dans certains cas (comme les séries temporelles), il est recommandé de ne pas mélanger les données pour conserver l’ordre chronologique.\n",
    "  \n",
    "\n",
    "Maintenant, utilisez la cellule suivante pour appliquer `train_test_split` et observer la structure de vos données d’entraînement et de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c690ff-b033-41b6-8cd1-3b80536c180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour diviser les données en ensembles d'entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90f9aa-1086-4762-ac48-d25b18f746c1",
   "metadata": {},
   "source": [
    "- **Vérification des dimensions des ensembles d'entraînement et de test avec `shape` :**\n",
    "   > **Question :** En utilisant la méthode `.shape`, les dimensions de `X_train` et `y_train` représentent-elles environ 80 % des données initiales ? Et celles de `X_test` et `y_test`, environ 20 % ?\n",
    "   \n",
    "   > **Question :** Pourquoi est-il important de maintenir une proportion équilibrée entre les ensembles d’entraînement et de test ?\n",
    "\n",
    "- **Impact de `random_state` sur la reproductibilité :**\n",
    "   > **Question :** Que se passe-t-il lorsque le paramètre `random_state` n’est pas fixé ? Lancez `train_test_split` sans spécifier `random_state=42` et comparez les résultats.\n",
    "\n",
    "   > **Question :** Pourquoi est-il avantageux d’obtenir la même division des données à chaque exécution du code ?\n",
    "\n",
    "- **Effet de `shuffle` sur la distribution des données :**\n",
    "   > **Question :** Si `shuffle` est défini sur `False` dans un dataset organisé par ordre, comment cela pourrait-il influencer l’entraînement et les performances du modèle ?\n",
    "\n",
    "   > **Question :** Dans quels types de problèmes serait-il pertinent de ne pas mélanger les données avant de les diviser en ensembles d’entraînement et de test ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b06678-3a29-4506-8893-3235b5d96ff4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Étape 5 : Entraînement des Modèles de Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e2ce6a-2909-4ec3-bc42-f5d87de12b34",
   "metadata": {},
   "source": [
    "L’entraînement d’un modèle consiste à utiliser les données d’entraînement pour permettre au modèle d’apprendre les relations entre les caractéristiques (`X_train`) et les labels de classe (`y_train`). Ce processus est la base du Machine Learning supervisé, où le modèle cherche à minimiser les erreurs dans ses prédictions en ajustant ses paramètres internes.\n",
    "\n",
    "Chaque modèle de Machine Learning a des spécificités, des avantages et des limitations en fonction des types de données, des distributions, et des tâches (précision, rapidité, interprétabilité, etc.). Dans cette section, nous allons explorer plusieurs modèles courants en classification, en présentant pour chacun :\n",
    "- Le principe de fonctionnement,\n",
    "- Les types de données pour lesquels il est adapté,\n",
    "- Ses sensibilités aux caractéristiques des données (par exemple, présence d’outliers, nécessité de normalisation),\n",
    "- Et les contextes où il est le plus performant.\n",
    "\n",
    "\n",
    "### Syntaxe Générale pour Instancier et Entraîner un Modèle\n",
    "\n",
    "Pour chaque modèle, l’entraînement suit cette structure de base en Python :\n",
    "\n",
    "```python\n",
    "from sklearn.model import ModelClass\n",
    "# Instancier et entraîner le modèle\n",
    "model = ModelClass()  # Instancie le modèle avec les paramètres par défaut\n",
    "model.fit(X_train, y_train)  # Entraîne le modèle sur les données d'entraînement\n",
    "```\n",
    "- **Explication :**\n",
    "    - **`ModelClass()`** : Cette instruction crée une instance du modèle que l’on souhaite utiliser. Par exemple, pour un modèle de K-Nearest Neighbors (KNN), ce sera `KNeighborsClassifier()`. En appelant la classe avec des paramètres par défaut, le modèle utilise des valeurs par défaut pour les hyperparamètres, mais il est possible de les spécifier pour adapter le modèle aux besoins spécifiques du projet (par exemple, `n_neighbors=5` pour KNN).\n",
    "\n",
    "    - **`.fit(X_train, y_train)`** : La méthode `.fit()` entraîne le modèle en ajustant ses paramètres internes pour minimiser les erreurs entre les prédictions et les valeurs réelles des classes dans `y_train`.  \n",
    "       - **`X_train`** : Ce sont les caractéristiques (features) des données d’entraînement que le modèle utilise pour trouver des motifs. Ce tableau contient uniquement les variables explicatives, sans la cible.\n",
    "       - **`y_train`** : Ce vecteur contient les labels de classe pour chaque observation de `X_train`. Le modèle apprend à associer les caractéristiques de chaque observation à sa classe réelle.\n",
    "\n",
    "Chaque modèle, une fois entraîné avec `.fit()`, pourra ensuite générer des prédictions sur de nouvelles données en utilisant la méthode `.predict()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b6689-bef9-4c76-8911-f6630cb6fefc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Modèle 1 : K-Nearest Neighbors (KNN)\n",
    "\n",
    "- **Principe du modèle :**  \n",
    "  KNN classe une observation en fonction des classes des `k` voisins les plus proches. Il calcule la distance entre l'observation à prédire et celles d’entraînement, puis assigne la classe majoritaire parmi les voisins les plus proches.\n",
    "\n",
    "- **Utilité :**  \n",
    "  Utile pour des problèmes où la similarité entre les points est cruciale. Idéal pour des jeux de données de petite à moyenne taille.\n",
    "\n",
    "- **Forces :**  \n",
    "  - Facile à comprendre et à implémenter.\n",
    "  - Performant sur des données bien séparées ou peu nombreuses.\n",
    "\n",
    "\n",
    "- **Limitations :**  \n",
    "  - Sensible à la dimension des données (devient coûteux en calculs lorsque le nombre de caractéristiques est élevé).\n",
    "  - Nécessite de stocker toutes les données d’entraînement, ce qui peut être lourd en mémoire.\n",
    "\n",
    "\n",
    "- **Pré-requis :**  \n",
    "  **Normalisation** des données souvent nécessaire, car KNN est sensible aux échelles des caractéristiques.\n",
    "\n",
    "\n",
    "- **Sensibilité aux valeurs aberrantes :**  \n",
    "  KNN est sensible aux valeurs aberrantes, qui peuvent influencer la classification via les calculs de distance.\n",
    "\n",
    "\n",
    "- **Paramètres clés :**  \n",
    "  - `n_neighbors` : Nombre de voisins à prendre en compte.\n",
    "  - `weights` : Pondération des voisins (uniforme ou selon la distance).\n",
    "  - `metric` : Type de distance (euclidienne par défaut).\n",
    "\n",
    "\n",
    "- **Classe d'importation :**  \n",
    "  `from sklearn.neighbors import KNeighborsClassifier`\n",
    "\n",
    "\n",
    "- **Documentation officielle :**  \n",
    "  [Documentation KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705f1d3-addb-4759-ba47-d44cbc4afd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciez et entraînez le modèle KNN ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb8bd8-b029-4827-b343-be19bea42ba2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Modèle 2 : Régression Logistique\n",
    "\n",
    "- **Principe du modèle :**  \n",
    "  La régression logistique est un modèle linéaire utilisant une fonction sigmoïde pour estimer les probabilités d’appartenance à une classe. Efficace pour les classifications binaires, et extensible aux classifications multiclasse.\n",
    "\n",
    "\n",
    "- **Utilité :**  \n",
    "  Particulièrement utile pour des problèmes de classification binaire et multiclasse lorsque les classes sont bien séparées par une frontière linéaire.\n",
    "\n",
    "\n",
    "- **Forces :**  \n",
    "  - Facile à interpréter et rapide à entraîner.\n",
    "  - Performant pour des relations linéaires entre caractéristiques et labels.\n",
    "\n",
    "- **Limitations :**  \n",
    "  - Moins performant pour les données non linéaires.\n",
    "  - Sensible aux multicolinéarités entre caractéristiques, ce qui peut affecter les coefficients du modèle.\n",
    "\n",
    "\n",
    "- **Pré-requis :**  \n",
    "  La **standardisation** des données est recommandée pour les modèles linéaires.\n",
    "\n",
    "\n",
    "- **Sensibilité aux valeurs aberrantes :**  \n",
    "  Sensible aux outliers, qui peuvent influencer la frontière de décision.\n",
    "\n",
    "\n",
    "- **Paramètres clés :**  \n",
    "  - `penalty` : Type de régularisation (par exemple, L1 pour la régularisation de Lasso et L2 pour la régularisation de Ridge).\n",
    "  - `C` : Inverse de la force de régularisation ; plus `C` est faible, plus la régularisation est forte.\n",
    "  - `solver` : Algorithme d’optimisation (comme ‘liblinear’ ou ‘saga’).\n",
    "\n",
    "\n",
    "- **Classe d'importation :**  \n",
    "  `from sklearn.linear_model import LogisticRegression`\n",
    "\n",
    "\n",
    "- **Documentation officielle :**  \n",
    "  [Documentation LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480178f-3c1a-4869-b010-9b3cc4f9fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciez et entraînez le modèle de Régression Logistique ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faceaa1a-9cf8-4f7a-8b7a-ba188446a7a0",
   "metadata": {},
   "source": [
    "### Modèle 3 : Support Vector Machine (SVM)\n",
    "\n",
    "- **Principe du modèle :**  \n",
    "  SVM maximise la marge entre les différentes classes en plaçant un hyperplan de séparation. Les points les plus proches de cet hyperplan (vecteurs de support) influencent la position de cet hyperplan.\n",
    "\n",
    "- **Utilité :**  \n",
    "  Performant pour la classification binaire dans des espaces de haute dimension, surtout lorsque les classes sont bien séparables.\n",
    "\n",
    "- **Forces :**  \n",
    "  - Performant pour les données de haute dimension.\n",
    "  - Peut séparer efficacement les données bien séparables avec des marges maximales.\n",
    "\n",
    "\n",
    "- **Limitations :**  \n",
    "  - Coût de calcul élevé pour les jeux de données de grande taille.\n",
    "  - Nécessite une sélection judicieuse des hyperparamètres (ex. : `C` et `gamma`).\n",
    "\n",
    "\n",
    "- **Pré-requis :**  \n",
    "  **Standardisation** des données recommandée pour les modèles basés sur les distances.\n",
    "\n",
    "\n",
    "- **Sensibilité aux valeurs aberrantes :**  \n",
    "  Sensible aux outliers, qui peuvent influencer la marge et donc l’hyperplan de séparation.\n",
    "\n",
    "\n",
    "- **Paramètres clés :**  \n",
    "  - `C` : Paramètre de régularisation.\n",
    "  - `kernel` : Type de noyau (linéaire, polynomial, radial, etc.).\n",
    "  - `gamma` : Influence des points dans la marge pour les noyaux non linéaires (comme le noyau RBF).\n",
    "\n",
    "\n",
    "- **Classe d'importation :**  \n",
    "  `from sklearn.svm import SVC`\n",
    "\n",
    "\n",
    "- **Documentation officielle :**  \n",
    "  [Documentation SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ecfee1-8f44-43cd-8eaf-9c8b87ed7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciez et entraînez le modèle SVM ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9927a37-9928-4eb2-8123-ea7361ea14f0",
   "metadata": {},
   "source": [
    "### Modèle 4 : Arbre de Décision (Decision Tree)\n",
    "\n",
    "- **Principe du modèle :**  \n",
    "  L'arbre de décision divise les données en sous-groupes basés sur des caractéristiques, formant une structure arborescente. Chaque nœud représente une décision, et chaque branche aboutit à une feuille, ou prédiction.\n",
    "  \n",
    "- **Utilité :**  \n",
    "  Utile pour des données complexes et non linéaires. Offre une interprétabilité facile et convient aux applications où les relations non linéaires sont importantes.\n",
    "\n",
    "\n",
    "- **Forces :**  \n",
    "  - Interprétable et facile à visualiser.\n",
    "  - Efficace pour des relations non linéaires et des ensembles de données mixtes (numériques et catégoriels).\n",
    "\n",
    "- **Limitations :**  \n",
    "  - Peut être sujet au surapprentissage (overfitting), surtout si l’arbre est profond.\n",
    "  - Moins performant sur les jeux de données très grands ou avec des classes imbriquées.\n",
    "\n",
    "\n",
    "- **Pré-requis :**  \n",
    "  Aucun prétraitement nécessaire (ni normalisation, ni standardisation).\n",
    "\n",
    "- **Sensibilité aux valeurs aberrantes :**  \n",
    "  Moins sensible aux valeurs aberrantes, bien que les arbres profonds puissent être influencés.\n",
    "\n",
    "\n",
    "- **Paramètres clés :**  \n",
    "  - `max_depth` : Profondeur maximale de l’arbre, pour éviter le surapprentissage.\n",
    "  - `min_samples_split` : Nombre minimum d’échantillons requis pour diviser un nœud.\n",
    "  - `criterion` : Mesure de l'impureté (par exemple, `gini` ou `entropy`).\n",
    "\n",
    "\n",
    "- **Classe d'importation :**  \n",
    "  `from sklearn.tree import DecisionTreeClassifier`\n",
    "\n",
    "\n",
    "- **Documentation officielle :**  \n",
    "  [Documentation DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823afbf-cc9e-4cee-b5ae-e562b9a0fd12",
   "metadata": {},
   "source": [
    "#### Exemple d'Arbre de Décision Simplifié\n",
    "\n",
    "Cet exemple illustre comment un arbre de décision pourrait être utilisé pour prédire si un client acceptera une offre de crédit en fonction de deux caractéristiques : **Revenu** et **Historique de crédit**.\n",
    "\n",
    "| **Revenu** | **Historique de crédit** | **Accepte offre** |\n",
    "|------------|--------------------------|--------------------|\n",
    "| Élevé      | Bon                      | Oui               |\n",
    "| Faible     | Mauvais                  | Non               |\n",
    "| Moyen      | Bon                      | Oui               |\n",
    "| Faible     | Bon                      | Non               |\n",
    "| Élevé      | Mauvais                  | Oui               |\n",
    "\n",
    "L'arbre de décision suivant peut représenter cette analyse :\n",
    "\n",
    "```\n",
    "               [Revenu?]\n",
    "                /      \\\n",
    "             Élevé     Faible\n",
    "            /            \\\n",
    "        [Crédit?]      Non (Feuille)\n",
    "           /    \\\n",
    "         Bon     Mauvais\n",
    "        /         \\\n",
    "       Oui       Non (Feuille)\n",
    "```\n",
    "\n",
    "\n",
    "#### Explication\n",
    "\n",
    "1. **Racine de l'arbre** : La première question posée est sur le **revenu** du client. Selon la réponse, l'arbre se divise en deux branches :\n",
    "   - **Élevé** : Les clients avec un revenu élevé continuent vers la question suivante sur leur historique de crédit.\n",
    "   - **Faible** : Les clients avec un revenu faible mènent directement à une prédiction \"Non\" pour l'offre de crédit.\n",
    "\n",
    "\n",
    "2. **Branches et feuilles** : \n",
    "   - Si le revenu est **élevé** et que l’**historique de crédit** est **bon**, l'arbre prédit \"Oui\".\n",
    "   - Si le revenu est **élevé** mais l’**historique de crédit** est **mauvais**, l'arbre prédit \"Non\".\n",
    "\n",
    "\n",
    "3. **Feuilles** : Les feuilles (Noeuds terminaux) représentent les décisions finales du modèle. Dans cet exemple, la feuille \"Oui\" signifie que le client acceptera l'offre, tandis que la feuille \"Non\" signifie qu’il ne l’acceptera pas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e44bb5-c61f-4294-8c8f-5fbdf0c7d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciez et entraînez le modèle Arbre de Décision ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3035a40e-5c11-4b89-b52e-9d6609321a14",
   "metadata": {},
   "source": [
    "### Modèle 5 : Forêt d'Arbres Décisionnels (Random Forest)\n",
    "\n",
    "- **Principe du modèle :**  \n",
    "  Random Forest combine plusieurs arbres de décision entraînés sur des sous-échantillons des données et utilise une moyenne des prédictions pour améliorer la précision et réduire le surapprentissage.\n",
    "\n",
    "- **Utilité :**  \n",
    "  Performant pour des données non linéaires et large échelle. Moins sensible au surapprentissage par rapport aux arbres de décision seuls.\n",
    "\n",
    "\n",
    "- **Forces :**  \n",
    "  - Moins sensible au surapprentissage grâce à la moyenne des prédictions de plusieurs arbres.\n",
    "  - Capable de gérer des caractéristiques de type mixte et des données avec des relations complexes.\n",
    "\n",
    "\n",
    "- **Limitations :**  \n",
    "  - Moins interprétable qu’un arbre de décision unique.\n",
    "  - Peut être coûteux en mémoire et en calcul pour des grands jeux de données.\n",
    "\n",
    "\n",
    "- **Pré-requis :**  \n",
    "  Aucun prétraitement spécifique requis (ni normalisation, ni standardisation).\n",
    "\n",
    "\n",
    "- **Sensibilité aux valeurs aberrantes :**  \n",
    "  Moins sensible aux valeurs aberrantes, car les prédictions sont basées sur l'agrégation de nombreux arbres.\n",
    "\n",
    "\n",
    "- **Paramètres clés :**  \n",
    "  - `n_estimators` : Nombre d’arbres dans la forêt.\n",
    "  - `max_depth` : Profondeur maximale de chaque arbre.\n",
    "  - `min_samples_split` : Nombre minimum d’échantillons requis pour diviser un nœud.\n",
    "\n",
    "\n",
    "- **Classe d'importation :**  \n",
    "  `from sklearn.ensemble import RandomForestClassifier`\n",
    "\n",
    "\n",
    "- **Documentation officielle :**  \n",
    "  [Documentation RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b1b1c-a6b8-4ea7-b47a-f71adf54081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciez et entraînez le modèle Random Forest ici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4358c-7760-4803-a0dc-5f2b4a71cb84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Étape 6 : Calcul des Prédictions pour Chaque Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0246867-d1d1-4e9c-8361-25d6f4512b14",
   "metadata": {
    "tags": []
   },
   "source": [
    "Après l'entraînement, nous utilisons chaque modèle pour prédire les classes sur les données de test (`X_test`). Cela nous permet de comparer les prédictions (`y_pred`) aux vraies valeurs (`y_test`) et de vérifier la capacité du modèle à généraliser.\n",
    "\n",
    "#### Syntaxe Générale\n",
    "\n",
    "```python\n",
    "# 4. Prédire les résultats\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "- **Explication** :\n",
    "   - `.predict(X_test)` : Utilise le modèle entraîné pour prédire les classes du jeu de test. `X_test` contient uniquement les caractéristiques (features) des données de test.\n",
    "   - `y_pred` : Vecteur contenant les prédictions de chaque observation dans `X_test`.\n",
    "\n",
    "#### Prédictions pour chaque modèle\n",
    "\n",
    "Utilisez la cellule suivante pour insérer le code de prédiction pour chaque modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3d5bf-282e-44e6-b7fc-7d3c3de0a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour prédire les classes avec le modèle KNN\n",
    "\n",
    "# Insérez votre code ici pour prédire les classes avec le modèle de Régression Logistique\n",
    "\n",
    "# Insérez votre code ici pour prédire les classes avec le modèle SVM\n",
    "\n",
    "# Insérez votre code ici pour prédire les classes avec le modèle Arbre de Décision\n",
    "\n",
    "# Insérez votre code ici pour prédire les classes avec le modèle Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d24191-c2a3-4fb3-9875-1c074b5ba426",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Questions\n",
    "\n",
    "1. **Précision des Prédictions :**\n",
    "   > **Question** : Quelle proportion des prédictions de `y_pred` correspond-elle aux vraies classes de `y_test` ?\n",
    "   \n",
    "   > **Question** : Les erreurs de prédiction sont-elles concentrées sur une classe spécifique ? Pourquoi cela pourrait-il être le cas ?\n",
    "\n",
    "2. **Analyse des Prédictions Incorrectes :**\n",
    "   > **Question** : Examinez quelques exemples de prédictions incorrectes. Identifiez-vous un schéma ou des caractéristiques communes parmi ces erreurs ?\n",
    "\n",
    "3. **Impact des Caractéristiques sur les Prédictions (pour les modèles linéaires) :**\n",
    "   > **Question** : Dans les modèles linéaires, certaines caractéristiques influencent-elles les prédictions plus que d’autres ? Comment les coefficients interprétables des modèles linéaires valident-ils ou remettent-ils en question vos intuitions ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3be20-5d0b-498d-b122-f8c89fe67264",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Étape 7 : Interprétation des Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf584cd-305a-4b6d-ab8d-3c3cff3a1a0f",
   "metadata": {},
   "source": [
    "L’interprétation des modèles consiste à comprendre comment chaque caractéristique influence les prédictions, en particulier en analysant les coefficients et l'importance des caractéristiques dans les modèles interprétables. Cela permet d’identifier les caractéristiques les plus influentes et de comprendre la logique des prédictions du modèle.\n",
    "\n",
    "### Syntaxe Générale pour Récupérer et Visualiser les Coefficients / Importance des Caractéristiques\n",
    "\n",
    "Pour les modèles **interprétables**, il est possible de récupérer et de visualiser l’influence des caractéristiques :\n",
    "\n",
    "- Les **coefficients** et l'**intercept** dans les modèles linéaires (régression logistique, SVM linéaire).\n",
    "- L’**importance des caractéristiques** dans les modèles basés sur les arbres (arbre de décision, forêts d'arbres).\n",
    "\n",
    "Un graphique en barres des coefficients ou des importances peut également aider à mieux comprendre l'impact de chaque caractéristique.\n",
    "\n",
    "\n",
    "#### 1. Récupérer et Visualiser les Coefficients et l’Intercept pour les Modèles Linéaires\n",
    "\n",
    "Les modèles linéaires comme la régression logistique et le SVM linéaire attribuent des coefficients à chaque caractéristique. L’interception (`intercept_`) représente le biais du modèle, soit le décalage par rapport à l’origine.\n",
    "\n",
    "```python\n",
    "# Récupérer les coefficients et l'intercept pour les modèles linéaires\n",
    "feature_names = X_train.columns  # Noms des caractéristiques\n",
    "coefficients = model.coef_[0]    # Coefficients pour un modèle linéaire comme LogisticRegression ou SVC\n",
    "intercept = model.intercept_[0]  # Interception (biais)\n",
    "\n",
    "# Visualiser les coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, coefficients)\n",
    "plt.xlabel(\"Importance des Coefficients\")\n",
    "plt.title(\"Importance des Caractéristiques dans un Modèle Linéaire\")\n",
    "plt.show()\n",
    "\n",
    "# Afficher l'intercept\n",
    "print(\"Intercept:\", intercept)\n",
    "```\n",
    "\n",
    "> **Note** : Les attributs `coef_` et `intercept_` sont applicables pour les modèles linéaires comme `LogisticRegression` et `SVC` (lorsque le noyau est linéaire `kernel='linear'`).\n",
    "                                                                               \n",
    "> **Important** : Les coefficients (`coef_`) sont uniquement disponibles pour le **SVM avec noyau linéaire** (`kernel='linear'`). Si un **noyau non linéaire** (comme `rbf`, `poly`, ou `sigmoid`) est utilisé, l’attribut `coef_` ne sera pas accessible. Dans ce cas, le modèle utilise une approche complexe qui rend l’interprétation directe des coefficients impossible. \n",
    "                                                                   \n",
    "\n",
    "#### 2. Récupérer et Visualiser l’Importance des Caractéristiques pour les Modèles Basés sur les Arbres\n",
    "\n",
    "Les modèles d’arbre de décision et les forêts d'arbres n'ont pas de coefficients ou d'intercept, mais ils attribuent une importance relative à chaque caractéristique. L’importance des caractéristiques est accessible via l'attribut `feature_importances_`.\n",
    "\n",
    "```python\n",
    "# Récupérer l'importance des caractéristiques pour les modèles basés sur les arbres\n",
    "importances = model.feature_importances_  # Importance des caractéristiques pour DecisionTreeClassifier ou RandomForestClassifier\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Visualiser l'importance des caractéristiques\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, importances)\n",
    "plt.xlabel(\"Importance des Caractéristiques\")\n",
    "plt.title(\"Importance des Caractéristiques dans un Modèle Basé sur les Arbres\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "> **Note** : `feature_importances_` est applicable aux modèles `DecisionTreeClassifier` et `RandomForestClassifier`.\n",
    "\n",
    "\n",
    "### Explication\n",
    "\n",
    "1. **`feature_names = X_train.columns`** : Récupère les noms des caractéristiques dans `X_train` pour les afficher sur l’axe des y du graphique.\n",
    "\n",
    "2. **Récupérer les coefficients et l’intercept (modèles linéaires)** :\n",
    "   - **`model.coef_[0]`** : Donne les coefficients associés à chaque caractéristique, qui indiquent l’influence de chaque variable dans le modèle.\n",
    "   - **`model.intercept_[0]`** : Donne l’intercept (biais), représentant le décalage de la fonction de prédiction par rapport à l’origine.\n",
    "\n",
    "3. **Récupérer l’importance des caractéristiques (modèles basés sur les arbres)** :\n",
    "   - **`model.feature_importances_`** : Donne une mesure d’importance de chaque caractéristique, indiquant la contribution moyenne d'une caractéristique dans la réduction d’impureté sur l’ensemble des arbres (Random Forest) ou sur les noeuds (Arbre de Décision).\n",
    "\n",
    "4. **Visualisation avec `plt.barh()`** :\n",
    "   - **Graphique en barres horizontales (`plt.barh`)** : Trace un graphique avec les noms des caractéristiques sur l’axe y et leurs coefficients ou importances respectives sur l’axe x. \n",
    "   - **`plt.xlabel` et `plt.title`** : Ajoutent des labels et un titre pour clarifier la visualisation.\n",
    "\n",
    "5. **Afficher l’intercept (si applicable)** :\n",
    "   - **`print(\"Intercept:\", intercept)`** : Affiche la valeur de l'interception, utile pour interpréter la prédiction de base lorsque toutes les caractéristiques sont à zéro (modèles linéaires seulement).\n",
    "\n",
    "Ce code permet d'explorer et de visualiser les influences des caractéristiques dans les modèles interprétables, en se basant sur leurs coefficients ou leur importance relative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4ac03-b295-4ec2-af80-c369891364f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Interprétation des Modèles\n",
    "\n",
    "L'interprétation des modèles en classification permet de comprendre comment chaque caractéristique influence les prédictions. Pour les modèles linéaires, on peut analyser les **coefficients**, et pour les modèles d’arbre, on utilise l'**importance des caractéristiques**. Cette section se concentre sur l’interprétation des caractéristiques et l’analyse des résultats de prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2f390-8139-497f-97f1-0adf0b97494d",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Régression Logistique\n",
    "\n",
    "- **Principe** : La régression logistique est un modèle linéaire qui utilise des coefficients pour chaque caractéristique afin de déterminer la probabilité d’appartenance à une classe.\n",
    "\n",
    "- **Interprétation des Coefficients** :\n",
    "  - En **classification binaire** (2 classes), chaque coefficient indique l'influence d'une caractéristique sur la probabilité de la classe positive (habituellement codée par `1`).\n",
    "  - En **classification multiclasses** (plus de 2 classes), le modèle utilise une approche \"un contre tous\" (one-vs-rest) avec un ensemble de coefficients pour chaque classe. La classe avec la probabilité la plus élevée est alors choisie comme la prédiction.\n",
    "  > **Note** : Pour obtenir les probabilités, utilisez directement `model.predict_proba()`\n",
    "\n",
    "- **Instructions** : Visualisez les coefficients pour observer l’influence de chaque caractéristique sur les prédictions. Un coefficient positif augmente la probabilité de la classe correspondante, tandis qu’un coefficient négatif la réduit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dd8f77-b357-4ce9-898b-2f952901b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour visualiser les coefficients de la régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a51705-eb83-4fe0-915f-04ed2d53bf2d",
   "metadata": {},
   "source": [
    "> **Questions** :\n",
    "  > - Quelles caractéristiques ont les coefficients les plus élevés ? Que suggère cela concernant leur impact sur la prédiction ?\n",
    "  > - Parmi les caractéristiques ayant des coefficients positifs, lesquelles augmentent le plus la probabilité d’une classe spécifique ?\n",
    "  > - Y a-t-il des caractéristiques avec des coefficients négatifs importants ? Comment pensez-vous qu'elles influencent la probabilité des classes ?\n",
    "  > - La classe avec la probabilité la plus élevée est-elle toujours la classe prédite ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a1c64-d0b9-410d-afcc-f6eb47ea643a",
   "metadata": {},
   "source": [
    "#### 2. SVM Linéaire (SVC avec `kernel='linear'`)\n",
    "\n",
    "- **Principe** : Le SVM linéaire est un modèle qui maximise la marge de séparation entre les classes, en utilisant des coefficients pour chaque caractéristique.\n",
    "\n",
    "- **Interprétation des Coefficients** :\n",
    "  - En **classification binaire**, chaque coefficient indique l’influence d'une caractéristique pour distinguer les deux classes.\n",
    "  - En **classification multiclasses** (plus de 2 classes), SVC utilise une approche \"un contre un\" (one-vs-one) pour entraîner des classificateurs binaires pour chaque paire de classes. La classe ayant le plus de \"votes\" parmi ces comparaisons est choisie comme la classe prédite.\n",
    "  \n",
    "  > **Note** : Utilisez `model.decision_function()` pour obtenir les scores de décision entre classes.\n",
    "\n",
    "- **Instructions** : Visualisez les coefficients pour chaque classe pour observer comment les caractéristiques influencent les décisions du modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac88fbf-fdf8-46f5-9f47-73bc0e156a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour visualiser les coefficients de SVC linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa78b7-2bca-4379-8292-34f22167545c",
   "metadata": {},
   "source": [
    "> **Questions** :\n",
    "  >- Quelles caractéristiques ont les coefficients les plus élevés pour chaque classe ? Comment influencent-elles la séparation des classes ?\n",
    "  >- Comment les caractéristiques influentes pour une paire de classes diffèrent-elles d'une autre paire de classes ?\n",
    "  >- Dans les cas où plusieurs classes sont proches en termes de scores de décision, qu'est-ce que cela suggère sur la difficulté de séparation entre ces classes ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ddf50-e66b-4c17-a54d-eda12d363fbb",
   "metadata": {},
   "source": [
    "#### 3. Arbre de Décision\n",
    "\n",
    "- **Principe** : L'arbre de décision divise les données en sous-groupes successifs en fonction de conditions sur les caractéristiques. La structure de l’arbre montre les décisions prises pour arriver à une prédiction.\n",
    "\n",
    "- **Interprétation de l'Importance des Caractéristiques** :\n",
    "  - Dans un arbre de décision, chaque caractéristique a une **importance** (`feature_importances_`) qui indique combien de fois cette caractéristique a été utilisée pour diviser les données.\n",
    "  - Une importance élevée signifie que la caractéristique est souvent utilisée pour faire des distinctions entre les classes.\n",
    "  \n",
    "    > **Note** : Utilisez `plot_tree()` pour afficher la structure de l’arbre et observer les décisions prises à chaque niveau.\n",
    "    \n",
    "- **Instructions** : Visualisez l’arbre pour observer comment chaque caractéristique est utilisée dans les divisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be54ba26-cb67-4b71-8a38-51f8aeda8be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour visualiser l'importance des caractéristiques dans l'arbre de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db40e010-4ec3-436b-8337-71a6cb5eefbe",
   "metadata": {},
   "source": [
    "> **Questions** :\n",
    "  >- Quelles caractéristiques apparaissent aux premiers niveaux de l'arbre ? Pourquoi pensez-vous qu'elles sont importantes pour diviser les données ?\n",
    "  >- Quelles caractéristiques ont l’importance la plus élevée selon `feature_importances_` ? Ces résultats sont-ils cohérents avec ce que vous attendiez ?\n",
    "  >- Lors de la visualisation de l’arbre, identifiez les chemins décisionnels pour une classe spécifique. Quelles caractéristiques semblent être déterminantes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217c5537-c5e5-4028-bb6f-75a1391d8e53",
   "metadata": {},
   "source": [
    "#### 4. Forêt d'Arbres Décisionnels (Random Forest)\n",
    "\n",
    "- **Principe** : Random Forest est un ensemble d’arbres de décision, où chaque arbre est entraîné sur un sous-échantillon des données. La prédiction finale est obtenue par vote majoritaire des prédictions de chaque arbre.\n",
    "\n",
    "- **Interprétation de l'Importance des Caractéristiques** :\n",
    "  - L'importance des caractéristiques dans Random Forest est la moyenne des importances observées dans chaque arbre de la forêt. Cette moyenne est accessible via `feature_importances_`.\n",
    "  \n",
    "  > **Note** : Utilisez `model.estimators_` pour visualiser des arbres individuels si besoin.\n",
    "  \n",
    "- **Instructions** : Visualisez l’importance des caractéristiques pour comprendre quelles caractéristiques influencent le plus les décisions globales du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcaa6f2-422e-453e-9ed2-8d41ec7b2c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour visualiser l'importance des caractéristiques dans la forêt d'arbres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcedb646-46de-44c2-8559-0c2fdd92538a",
   "metadata": {},
   "source": [
    "> **Questions** :\n",
    "  >- Quelles caractéristiques ont la plus grande importance moyenne ? Pourquoi pensez-vous qu'elles influencent globalement la forêt ?\n",
    "  >- Les caractéristiques importantes sont-elles cohérentes avec celles observées dans l’arbre de décision unique ? Pourquoi ou pourquoi pas ?\n",
    "  >- Comment des caractéristiques avec des importances moyennes faibles pourraient-elles encore jouer un rôle dans les prédictions individuelles d’arbres spécifiques ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb31d217-4693-4a6f-981c-7d6e3faefa69",
   "metadata": {},
   "source": [
    "#### 5. K-Nearest Neighbors (KNN)\n",
    "\n",
    "- **Principe** : KNN classe une observation en fonction des classes des `k` voisins les plus proches dans l’espace des caractéristiques. Il ne possède pas de coefficients ou d’importance des caractéristiques.\n",
    "\n",
    "- **Interprétation** :\n",
    "  - KNN est influencé par les distances aux voisins. La normalisation des caractéristiques peut avoir un impact important sur les résultats, car les caractéristiques avec des échelles différentes affecteront les distances de manière inégale.\n",
    "\n",
    "- **Instructions** : Expérimentez avec la normalisation des données et différentes valeurs de `k` pour observer leur impact sur les prédictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42010d0-42f8-44ee-a0af-cc9dd25886bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour expérimenter avec différentes valeurs de k et observer les prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ab7b1-cec2-4e12-a561-917986812181",
   "metadata": {},
   "source": [
    "> **Questions d’Interprétation** :\n",
    "  >- Comment la normalisation ou standardisation des caractéristiques affecte-t-elle les voisins les plus proches et les prédictions ?\n",
    "  >- Comment le choix de `k` influence-t-il les prédictions et la stabilité des résultats ?\n",
    "  >- Dans quels cas les observations de classes différentes peuvent-elles se retrouver très proches les unes des autres ? Quelles implications cela peut-il avoir sur la précision des prédictions de KNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b6d61-a4f5-40a2-a316-59497088ccb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "--- \n",
    "## Étape 8 : Évaluation des Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911256f2-073c-4895-a829-677d99d0e158",
   "metadata": {},
   "source": [
    "Pour évaluer les performances d’un modèle d'apprentissage supervisé, nous avons recours à diverses métriques d’évaluation, qui permettent d’interpréter les résultats en fonction des objectifs spécifiques du projet.\n",
    "\n",
    "\n",
    "### Syntaxe Générale pour l'Évaluation\n",
    "\n",
    "Utilisez cette structure pour évaluer les performances de chaque modèle avec les fonctions de `sklearn.metrics` :\n",
    "\n",
    "```python\n",
    "# Évaluer le modèle avec des métriques de classification\n",
    "from sklearn import metrics\n",
    "score = metrics.some_metric(y_test, y_pred)  # Remplacez some_metric par la métrique souhaitée\n",
    "```\n",
    "\n",
    "**Évaluation avec `metrics` de `sklearn`** :\n",
    "   - Le module `metrics` fournit de nombreuses fonctions pour évaluer les performances d’un modèle. Par exemple, en classification, vous pouvez utiliser `accuracy_score` (exactitude), `precision_score` (précision), `recall_score` (rappel), et `f1_score`. En régression, des métriques comme `mean_squared_error` mesurent l’erreur quadratique moyenne.\n",
    "   - Le choix des métriques dépend de la tâche (classification ou régression) et des priorités du projet (minimiser les erreurs positives ou négatives, par exemple).\n",
    "\n",
    "Pour évaluer les performances d’un modèle de classification, la **matrice de confusion** est souvent utilisée comme point de départ. Elle permet de visualiser les prédictions correctes et incorrectes pour chaque classe, et fournit les informations nécessaires pour calculer les principales métriques de performance.\n",
    "\n",
    "### Matrice de Confusion\n",
    "\n",
    "La **matrice de confusion** est un tableau qui présente les prédictions correctes et incorrectes par classe. Elle est structurée de façon à montrer les **Vrais Positifs (VP)**, **Faux Négatifs (FN)**, **Faux Positifs (FP)**, et **Vrais Négatifs (VN)**, ce qui facilite le calcul des métriques d’évaluation.\n",
    "\n",
    "|                    | Prédit : Positif          | Prédit : Négatif           |\n",
    "|--------------------|---------------------------|-----------------------------|\n",
    "| **Réel : Positif** | <span style=\"color:green\">Vrais Positifs (VP)</span> | <span style=\"color:red\">Faux Négatifs (FN)</span> |\n",
    "| **Réel : Négatif** | <span style=\"color:red\">Faux Positifs (FP)</span>    | <span style=\"color:green\">Vrais Négatifs (VN)</span> |\n",
    "\n",
    "**Interprétation** :\n",
    "- **Vrais Positifs (VP)** : Observations correctement classées comme positives.\n",
    "- **Faux Négatifs (FN)** : Observations positives mal classées comme négatives.\n",
    "- **Faux Positifs (FP)** : Observations négatives mal classées comme positives.\n",
    "- **Vrais Négatifs (VN)** : Observations correctement classées comme négatives.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Utilisez `confusion_matrix` de `sklearn.metrics` pour visualiser et interpréter les erreurs de classification. La matrice de confusion affiche les prédictions correctes et incorrectes pour chaque classe, ce qui aide à identifier les types d’erreurs du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f91703-f905-4204-99d2-1b81304256f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour calculer et afficher la matrice de confusion de chaque modele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b74c7c-0e75-48c1-9fb8-30c9abb2d282",
   "metadata": {},
   "source": [
    "**Instructions** :\n",
    "1. Calculez la matrice de confusion pour observer les erreurs de prédiction.\n",
    "2. Interprétez les valeurs de faux positifs (FP) et de faux négatifs (FN) pour comprendre où le modèle se trompe le plus.\n",
    "\n",
    "**Questions** :\n",
    "   - Quels sont les éléments principaux dans la diagonale de la matrice de confusion ? Que représentent-ils ?\n",
    "   - Quels sont les éléments hors diagonale ? Que peut-on en déduire sur les erreurs du modèle ?\n",
    "   - Dans quelles classes observe-t-on le plus d’erreurs de prédiction (FP ou FN) ? À quoi cela pourrait-il être dû ?\n",
    "\n",
    "> **Note** : Pour un problème de classification avec plusieurs classes, comme le jeu de données Iris (3 classes), la matrice de confusion est une matrice carrée de taille \\( n \\times n \\) où \\( n \\) est le nombre de classes. Chaque case \\( (i, j) \\) de la matrice représente le nombre d'observations de la classe réelle \\( i \\) qui ont été prédites comme appartenant à la classe \\( j \\). Les valeurs sur la diagonale indiquent les prédictions correctes pour chaque classe, tandis que les valeurs hors diagonale montrent les erreurs de classification.\n",
    "\n",
    "**Exemple dans le cas d'Iris** :\n",
    "   - Supposons que nous avons les classes **Setosa (0)**, **Versicolor (1)**, et **Virginica (2)**.\n",
    "   - Un **faux positif (FP)** pour la classe Versicolor se produit lorsqu’une observation Virginica ou Setosa est incorrectement classée comme Versicolor.\n",
    "   - Un **faux négatif (FN)** pour la classe Virginica se produit lorsqu’une observation Virginica est incorrectement classée comme Setosa ou Versicolor.\n",
    "\n",
    "Ces erreurs peuvent être dues à une similarité entre certaines caractéristiques des classes Virginica et Versicolor, rendant la séparation entre elles plus difficile pour le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66800de9-a4cd-47a5-ad3c-b71a8d6628eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Métriques d’Évaluation en Classification\n",
    "\n",
    "Ces métriques sont basées sur la **matrice de confusion** et permettent d'interpréter les résultats en fonction des objectifs du projet.\n",
    "\n",
    "#### 1. **Accuracy** : Le pourcentage de prédictions correctes parmi toutes les prédictions.\n",
    "   - **Formule** :$ \\text{Accuracy} = \\frac{\\text{VP + VN}}{\\text{Total des Prédictions}} $\n",
    "   - **Fonction dans `sklearn`** : `metrics.accuracy_score`\n",
    "   - **Interprétation** : Mesure globale de la performance. Une accuracy élevée signifie que le modèle effectue correctement la majorité des prédictions.\n",
    "   - **Utilité** : Indicateur simple et efficace lorsque les classes sont **équilibrées**. Cependant, si une classe est dominante (déséquilibre), l’accuracy peut être trompeuse.\n",
    "   - **Exemple** : Dans la classification d’images de vêtements, si les catégories sont équilibrées (par ex. chaussures vs t-shirts), l’accuracy donne une bonne idée de la performance globale. En revanche, pour des données déséquilibrées, comme la détection de défauts dans une chaîne de production, une accuracy élevée pourrait ne refléter que la dominance de la classe majoritaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fe281-d3c9-44be-8d52-cd45a891c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour calculer l'accuracy pour chaque modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77837a8e-ed0d-4e05-abca-02337b72e9c1",
   "metadata": {},
   "source": [
    ">**Questions** :\n",
    "   >- L’accuracy est-elle similaire entre les modèles ? Qu’est-ce que cela indique sur la performance globale de chaque modèle ?\n",
    "   >- Dans un cas de classes équilibrées, pensez-vous que l'accuracy est une mesure fiable pour évaluer la performance ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a5078b-1d27-4090-8c6b-8b21f935b461",
   "metadata": {},
   "source": [
    "#### 2. **Précision (Precision)** : Proportion des prédictions positives qui sont correctes.\n",
    "   - **Formule** : $ \\text{Précision} = \\frac{\\text{VP}}{\\text{VP + FP}} $\n",
    "   - **Fonction dans `sklearn`** : `metrics.precision_score` avec le paramètre `average='macro'` ou `average='weighted'` pour les cas multiclasses.\n",
    "   > **Note pour les cas multiclasses** :  \n",
    "   >- **`average='macro'`** : Calcule la métrique indépendamment pour chaque classe, puis fait la moyenne. Cela donne un poids égal à chaque classe, quelle que soit sa fréquence.\n",
    "   >- **`average='weighted'`** : Calcule la métrique pour chaque classe puis fait une moyenne pondérée selon la fréquence de chaque classe. Cela prend en compte le déséquilibre des classes pour refléter plus fidèlement la performance globale.\n",
    "   - **Interprétation** : La précision mesure la fiabilité des prédictions positives du modèle. Une précision élevée indique que le modèle commet peu d’erreurs lorsqu’il prédit une observation positive.\n",
    "   - **Utilité** : Essentielle lorsque les **faux positifs sont coûteux** ou indésirables. On favorise une haute précision lorsque l’on souhaite éviter de prédire positivement à tort.\n",
    "   - **Exemple** : En **détection de fraudes**, une fausse alerte (faux positif) est coûteuse car elle pourrait entraîner des enquêtes inutiles. Une haute précision signifie que les transactions signalées sont très probablement frauduleuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785bee10-bf65-4220-ac45-0e860b37b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour calculer la précision pour chaque modèle (cas multiclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740da129-e7d1-45d9-bce2-894bc583a437",
   "metadata": {},
   "source": [
    ">**Questions** :\n",
    "   >- La précision est-elle équilibrée entre les classes et entre les modèles ?\n",
    "   >- Pour ce projet, une précision élevée est-elle plus importante qu’un bon rappel ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e600e-86cf-4dfb-977a-fb6e57905e93",
   "metadata": {},
   "source": [
    "#### 3. **Rappel (Recall)** : Proportion des instances positives correctement identifiées par le modèle.\n",
    "   - **Formule** : $ \\text{Rappel} = \\frac{\\text{VP}}{\\text{VP + FN}} $\n",
    "   - **Fonction dans `sklearn`**: `metrics.recall_score`avec le paramètre `average='macro'` ou `average='weighted'` pour les cas multiclasses.\n",
    "   - **Interprétation** : Le rappel mesure la capacité du modèle à capturer toutes les instances positives. Un rappel élevé indique que le modèle détecte bien les cas positifs.\n",
    "   - **Utilité** : Crucial quand il est important de **minimiser les faux négatifs**, notamment lorsque chaque cas positif manqué a de graves conséquences.\n",
    "   - **Exemple** : Dans le **dépistage médical**, comme le dépistage du cancer, un haut rappel est essentiel car chaque faux négatif (cas positif non détecté) pourrait passer inaperçu. Le modèle doit donc être très sensible aux cas positifs pour détecter le plus grand nombre de cas possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc97c8-72f5-4280-bd28-d3f5c66528dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour calculer le rappel pour chaque modèle (cas multiclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cbca56-38f5-4860-9364-26fc87b392da",
   "metadata": {},
   "source": [
    " >**Questions** :\n",
    "   >- Les valeurs de rappel sont-elles similaires pour chaque classe et chaque modèle ?\n",
    "   >- Pour ce projet, est-il préférable d’optimiser le rappel ou la précision ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69528d70-1f7f-45d0-9226-9890a7ddffa1",
   "metadata": {},
   "source": [
    "#### 4. **F1-Score** : Moyenne harmonique entre la précision et le rappel.\n",
    "   - **Formule** : $ \\text{F1-Score} = 2 \\cdot \\frac{\\text{Précision} \\times \\text{Rappel}}{\\text{Précision + Rappel}} $\n",
    "   - **Fonction dans `sklearn`** : `metrics.f1_score` avec le paramètre `average='macro'` ou `average='weighted'` pour les cas multiclasses.\n",
    "   - **Interprétation** : Le F1-score équilibre la précision et le rappel. Un F1-score élevé signifie que le modèle a une bonne performance globale sans sacrifier l’une des deux métriques.\n",
    "   - **Utilité** : Particulièrement utile lorsque les **classes sont déséquilibrées** ou lorsque l’on veut à la fois limiter les faux positifs et les faux négatifs.\n",
    "   - **Exemple** : Dans la **détection de spams**, un bon F1-score est souhaitable pour minimiser les emails légitimes classés comme spams (précision) tout en capturant efficacement les spams (rappel), offrant ainsi un équilibre entre précision et rappel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772b6c6-07fb-4254-9d38-e160f6fced5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour calculer le F1-score pour chaque modèle (cas multiclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c0ca4-2ddc-442f-a1f9-07c792c748d3",
   "metadata": {},
   "source": [
    ">**Questions** :\n",
    "   >- Le F1-score est-il le même entre les classes et les modèles ?\n",
    "   >- Le F1-score le plus élevé correspond-il également au meilleur équilibre précision/rappel pour le modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99042c-8653-4a27-bdb2-e15b1785a752",
   "metadata": {},
   "source": [
    "#### Instructions pour Regrouper et Comparer les Résultats\n",
    "\n",
    "1. **Regroupez les résultats** : Compilez les résultats des métriques (accuracy, précision, rappel, F1-score) pour chaque modèle dans un tableau ou une structure, ce qui facilitera la comparaison.\n",
    "2. **Analysez les performances** : Comparez les modèles en fonction des valeurs de chaque métrique pour déterminer lequel est le plus adapté aux objectifs du projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed3824-9738-42fa-9ff5-d4cd39c1296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insérez votre code ici pour regrouper les résultats de toutes les métriques et faciliter la comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde478ca-82c9-45aa-af41-a17fe2f7e1f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Interprétation des Résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c49395-b8ce-4d93-84b1-34b217c23c2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Après avoir calculé et regroupé les métriques pour chaque modèle, il est essentiel d’analyser ces résultats afin d’identifier le modèle le mieux adapté aux objectifs du projet. Cette section vous guidera dans l’interprétation des métriques et des différences entre les modèles, tout en prenant en compte les compromis possibles.\n",
    "\n",
    "#### 1. Comparaison des Performances des Modèles\n",
    "\n",
    "   - **Analyse des Métriques** : Comparez chaque modèle sur l’ensemble des métriques (accuracy, précision, rappel, F1-score) pour identifier les forces et faiblesses spécifiques.\n",
    "      - Un modèle avec une **accuracy** élevée peut indiquer une bonne performance générale, mais cette métrique peut être trompeuse en cas de classes déséquilibrées.\n",
    "      - La **précision** révèle la fiabilité des prédictions positives, ce qui est essentiel lorsque les faux positifs sont coûteux.\n",
    "      - Le **rappel** montre la capacité du modèle à capturer tous les cas positifs, important pour minimiser les faux négatifs dans des applications sensibles comme le diagnostic médical.\n",
    "      - Le **F1-score** offre un bon équilibre entre précision et rappel, particulièrement utile lorsque les faux positifs et les faux négatifs ont un coût similaire.\n",
    "\n",
    "   **Questions** :\n",
    "   - Quels modèles montrent des performances similaires ou des différences marquées sur certaines métriques ?\n",
    "   - Quel modèle semble le mieux adapté aux objectifs du projet et à ses besoins (ex. haute précision, rappel) ?\n",
    "\n",
    "#### 2. Analyse des Forces et Faiblesses de Chaque Modèle\n",
    "\n",
    "   - **Forces des Modèles** : Identifiez les points forts en fonction des métriques clés. Par exemple :\n",
    "      - Les modèles avec une précision élevée sont fiables pour les prédictions positives, réduisant les erreurs de faux positifs.\n",
    "      - Les modèles ayant un bon rappel détectent mieux les cas positifs, ce qui peut être crucial dans des domaines comme la santé.\n",
    "\n",
    "   - **Faiblesses des Modèles** : Notez les faiblesses éventuelles, comme un faible rappel ou une précision réduite, et réfléchissez à leur impact dans le contexte du projet.\n",
    "\n",
    "   **Questions** :\n",
    "   - Pour chaque modèle, quelles faiblesses peuvent être acceptées et quelles devraient être minimisées en fonction des objectifs du projet ?\n",
    "   - En quoi les forces et les faiblesses de chaque modèle influencent-elles votre choix final ?\n",
    "\n",
    "#### 3. Impact des Erreurs : Faux Positifs et Faux Négatifs\n",
    "\n",
    "   - **Faux Positifs (FP)** : Les faux positifs surviennent lorsque le modèle classe une observation comme positive alors qu’elle ne l’est pas. Ils sont problématiques lorsque les faux positifs entraînent des actions coûteuses ou inutiles.\n",
    "   - **Faux Négatifs (FN)** : Les faux négatifs se produisent lorsque le modèle échoue à détecter un cas positif. Ils sont critiques dans des situations où les cas positifs manqués peuvent avoir des conséquences graves (par exemple, un diagnostic médical manqué).\n",
    "\n",
    "   **Questions** :\n",
    "   - Dans le contexte de ce projet, quel type d’erreur (FP ou FN) est-il le plus problématique ?\n",
    "   - Quel modèle semble minimiser le type d’erreur le plus critique pour ce projet ?\n",
    "\n",
    "#### 4. Sélection Finale du Modèle\n",
    "\n",
    "   - **Choix du Modèle Optimal** : Sur la base des métriques et de l’analyse des erreurs, choisissez le modèle qui répond le mieux aux objectifs du projet.\n",
    "   - **Justification du Choix** : Expliquez pourquoi ce modèle est le plus adapté en tenant compte des résultats d’évaluation et des implications des erreurs.\n",
    "\n",
    "   **Questions** :\n",
    "   - En quoi les objectifs du projet influencent-ils le choix final du modèle ?\n",
    "   - Y a-t-il un compromis entre les métriques qui justifie votre choix final ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af25f90f-a5d2-43e6-a6f7-9662101ba84b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Challenges de la Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7836cc24-fc58-4c8a-97e4-75f313d608c6",
   "metadata": {},
   "source": [
    "La classification est une tâche fondamentale en Machine Learning, mais elle présente également de nombreux défis. Comprendre ces challenges aide à construire des modèles plus robustes et à mieux interpréter les résultats.\n",
    "\n",
    "#### 1. **Classes Déséquilibrées**\n",
    "\n",
    "   - **Description** : Lorsque certaines classes sont beaucoup plus représentées que d’autres, cela peut conduire à des modèles biaisés qui privilégient la classe majoritaire. Par exemple, dans un dataset où 95 % des échantillons appartiennent à une classe \"non défaut\" et 5 % à une classe \"défaut\", un modèle peut atteindre une accuracy élevée simplement en prédisant toujours \"non défaut\".\n",
    "   - **Solutions** :\n",
    "      - Utiliser des techniques d’échantillonnage (sous-échantillonnage de la classe majoritaire ou suréchantillonnage de la classe minoritaire).\n",
    "      - Essayer des algorithmes spécifiques pour données déséquilibrées, comme **Balanced Random Forest**.\n",
    "      - Utiliser des métriques comme le **F1-score**, le **rappel** ou l’**AUC-ROC** qui prennent mieux en compte l’équilibre des classes.\n",
    "   - **Questions de Réflexion** :\n",
    "      - Votre dataset est-il déséquilibré ? Si oui, quel impact cela pourrait-il avoir sur la performance du modèle ?\n",
    "      - Quelle métrique de performance serait la plus appropriée pour évaluer un modèle sur des classes déséquilibrées ?\n",
    "\n",
    "#### 2. **Overfitting (Surapprentissage)**\n",
    "\n",
    "   - **Description** : L’overfitting se produit lorsqu'un modèle apprend trop bien les détails spécifiques des données d’entraînement, au point qu’il devient incapable de généraliser sur de nouvelles données. Cela peut survenir lorsque le modèle est trop complexe ou n’a pas été suffisamment régularisé.\n",
    "   - **Solutions** :\n",
    "      - Utiliser une validation croisée pour évaluer la capacité de généralisation du modèle.\n",
    "      - Appliquer des techniques de régularisation (par ex. régularisation L2 dans la régression logistique).\n",
    "      - Réduire la complexité du modèle en ajustant des hyperparamètres, comme la profondeur des arbres de décision ou le nombre de voisins pour KNN.\n",
    "   - **Questions de Réflexion** :\n",
    "      - Comment identifiez-vous les signes d’overfitting dans un modèle ?\n",
    "      - Quelles actions pourriez-vous entreprendre si vous constatez que votre modèle montre des signes de surapprentissage ?\n",
    "\n",
    "#### 3. **Underfitting (Sous-apprentissage)**\n",
    "\n",
    "   - **Description** : L’underfitting se produit lorsque le modèle est trop simple pour capturer les relations importantes dans les données, ce qui entraîne des performances faibles sur l’ensemble d’entraînement et sur l’ensemble de test.\n",
    "   - **Solutions** :\n",
    "      - Augmenter la complexité du modèle (par ex. en utilisant plus de paramètres dans un modèle linéaire ou en ajoutant plus de couches dans un réseau de neurones).\n",
    "      - Tester des modèles plus complexes qui pourraient mieux capturer les motifs dans les données.\n",
    "   - **Questions de Réflexion** :\n",
    "      - Comment pouvez-vous savoir si votre modèle est trop simple pour les données ?\n",
    "      - Quelles sont les conséquences de l’underfitting sur la performance globale du modèle ?\n",
    "\n",
    "![overfitting_underfitting_classification](overfitting_underfitting_classification.png)\n",
    "\n",
    "#### 4. **Data Leakage (Fuite de Données)**\n",
    "\n",
    "   - **Description** : Le data leakage survient lorsque des informations du dataset de test (ou des données futures) se retrouvent indirectement dans le dataset d’entraînement. Cela fausse les résultats et entraîne un modèle optimiste qui ne performe pas bien sur de nouvelles données.\n",
    "   - **Solutions** :\n",
    "      - Effectuer toutes les étapes de transformation (normalisation, encodage, etc.) **après** la division des données en ensembles d’entraînement et de test.\n",
    "      - Veiller à ce qu’aucune variable ne contienne d’informations qui ne devraient pas être connues avant la prédiction.\n",
    "   - **Questions de Réflexion** :\n",
    "      - Quelles étapes du prétraitement doivent être effectuées après la séparation en train/test pour éviter le data leakage ?\n",
    "      - Quels indicateurs dans vos résultats peuvent révéler un possible data leakage ?\n",
    "\n",
    "#### 5. **Choix de la Bonne Métrique d’Évaluation**\n",
    "\n",
    "   - **Description** : Dans certains contextes, l’accuracy seule peut être trompeuse, surtout en présence de classes déséquilibrées ou lorsque certains types d’erreurs (faux positifs ou faux négatifs) sont plus coûteux que d’autres.\n",
    "   - **Solutions** :\n",
    "      - Utiliser des métriques adaptées au contexte, telles que le **précision**, le **rappel**, le **F1-score**, et le **AUC-ROC**.\n",
    "      - Effectuer une analyse de la matrice de confusion pour comprendre le type d’erreurs que le modèle fait fréquemment.\n",
    "   - **Questions de Réflexion** :\n",
    "      - Quelle(s) métrique(s) pourriez-vous privilégier dans le cadre de votre projet, et pourquoi ?\n",
    "      - Comment la matrice de confusion vous aide-t-elle à mieux interpréter les performances du modèle ?\n",
    "\n",
    "#### 6. **Interprétabilité du Modèle**\n",
    "\n",
    "   - **Description** : Certains modèles complexes, comme les forêts d’arbres ou les réseaux de neurones, offrent de bonnes performances mais manquent d’interprétabilité, ce qui peut poser des problèmes pour comprendre les décisions prises par le modèle, surtout dans des secteurs réglementés comme le secteur bancaire.\n",
    "   - **Solutions** :\n",
    "      - Utiliser des techniques d’interprétation des modèles (ex. **SHAP**, **LIME**) pour comprendre l’influence de chaque caractéristique sur les prédictions.\n",
    "      - Privilégier des modèles plus interprétables (ex. régression logistique) si les performances sont acceptables et que l’interprétation est cruciale.\n",
    "   - **Questions de Réflexion** :\n",
    "      - Quels sont les avantages et les inconvénients d’utiliser un modèle interprétable versus un modèle complexe ?\n",
    "      - Dans quelles situations est-il essentiel de privilégier l’interprétabilité du modèle par rapport à la précision ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13cd6f9-a506-4f33-b751-fb986bbbc5b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "---\n",
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4954c4c4-4799-4a94-9a2b-093afc494ec7",
   "metadata": {},
   "source": [
    "Dans cette séance, nous avons exploré les principes de base de l’**apprentissage supervisé** et appliqué un workflow complet pour construire et évaluer des modèles de classification. Voici les principaux points abordés :\n",
    "\n",
    "- **Apprentissage Supervisé** :\n",
    "  - Le modèle apprend à prédire des classes ou des valeurs à partir de données étiquetées.\n",
    "  - Un ensemble de données d’entraînement permet de comprendre les relations entre les caractéristiques et les classes, facilitant ainsi les prédictions sur de nouvelles données.\n",
    "\n",
    "- **Workflow Rigoureux** :\n",
    "  - Le processus suivi inclut des étapes clés :\n",
    "    - **Extraction et Exploration des Données** : Analyse et compréhension initiale des données pour identifier les caractéristiques importantes et détecter d’éventuelles anomalies.\n",
    "    - **Préparation des Données** : Nettoyage et prétraitement des données pour améliorer la qualité du modèle.\n",
    "    - **Division en Ensembles d’Entraînement et de Test** : Assure une évaluation fiable des performances en séparant les données d’entraînement des données de test.\n",
    "    - **Entraînement du Modèle** : Apprentissage du modèle à partir des données d’entraînement.\n",
    "    - **Évaluation des Performances** : Utilisation de métriques pour analyser et comparer les performances du modèle.\n",
    "\n",
    "- **Classification et Évaluation des Modèles** :\n",
    "  - Nous avons exploré plusieurs métriques d’évaluation pour analyser les performances des modèles : **accuracy**, **précision**, **rappel** et **F1-score**. \n",
    "  - Ces métriques fournissent une vue complète des forces et des faiblesses de chaque modèle, particulièrement en classification multiclasses.\n",
    "\n",
    "- **Applicabilité à d’autres Modèles de Classification** :\n",
    "  - Bien que cette séance ait principalement utilisé le dataset Iris, le workflow et les métriques d’évaluation peuvent s’appliquer à une large gamme de modèles de classification, tels que :\n",
    "    - **Régression Logistique**\n",
    "    - **k-nearest neighbors (KNN)**\n",
    "    - **Forêts aléatoires (Random Forest)**\n",
    "    - **Machines à vecteurs de support (SVM)**\n",
    "  - Chacun de ces modèles peut être choisi en fonction des besoins spécifiques du projet et offre des applications diversifiées en classification supervisée.\n",
    "\n",
    "En résumé, cette séance a permis de consolider une méthodologie robuste applicable à tout projet de classification supervisée, offrant une base solide pour évaluer de manière rigoureuse les performances de différents modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa7e3f-b7ce-4061-ae87-14c18bad67fa",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
